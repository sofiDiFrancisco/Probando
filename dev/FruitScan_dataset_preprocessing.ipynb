{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e210c4",
   "metadata": {},
   "source": [
    "# FruitScan - Preprocesamiento del Dataset\n",
    "Este notebook realiza el preprocesamiento de imágenes del dataset `Fruit Quality` para usar en un modelo de detección de defectos con PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b8090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuración inicial\n",
    "DATA_DIR = \"./data/FruitQuality\"  # Ruta al dataset descargado y organizado\n",
    "BATCH_SIZE = 8\n",
    "IMG_SIZE = 224\n",
    "VAL_SPLIT = 0.2\n",
    "SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f006e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Transformaciones (aumentos opcionales)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Imagen RGB\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65232f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Dataset a partir de carpetas\n",
    "dataset = datasets.ImageFolder(root=DATA_DIR, transform=transform)\n",
    "class_names = dataset.classes\n",
    "\n",
    "# 4. Dividir en entrenamiento y validación\n",
    "torch.manual_seed(SEED)\n",
    "val_size = int(len(dataset) * VAL_SPLIT)\n",
    "train_size = len(dataset) - val_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacd0681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0621cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Visualización rápida\n",
    "def show_sample(loader):\n",
    "    images, labels = next(iter(loader))\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(12, 3))\n",
    "    for i in range(4):\n",
    "        img = images[i].permute(1, 2, 0)  # CHW -> HWC\n",
    "        img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
    "        ax[i].imshow(img)\n",
    "        ax[i].set_title(class_names[labels[i]])\n",
    "        ax[i].axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "show_sample(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1648cd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Guardar información útil\n",
    "torch.save({\n",
    "    'class_names': class_names,\n",
    "    'transform': transform\n",
    "}, 'data/fruitscan_meta.pth')\n",
    "\n",
    "print(\"✅ Dataset preprocesado y listo para entrenamiento.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
